{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/payal6269/first-project/blob/main/assignment6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: Create a file that contains 1000 lines of random strings."
      ],
      "metadata": {
        "id": "oh4c8WOzYanv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUhFgqjIYWlC"
      },
      "outputs": [],
      "source": [
        "  import random\n",
        "  import string\n",
        "\n",
        "  with open('random_strings.txt', 'w') as f:\n",
        "      for _ in range(1000):\n",
        "          f.write(''.join(random.choices(string.ascii_letters + string.digits, k=10)) + '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2: Create a file with multiple lines of random strings, file size must be 5 MB."
      ],
      "metadata": {
        "id": "2qBiGCPeYnDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  num_lines = 5000  # Approx. assuming 1 line ~1KB\n",
        "  with open('random_strings_5mb.txt', 'w') as f:\n",
        "      for _ in range(num_lines):\n",
        "          f.write(''.join(random.choices(string.ascii_letters + string.digits, k=100)) + '\\n')\n"
      ],
      "metadata": {
        "id": "EUv1XeV3YooG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3: Create 10 files with multiple lines of random strings, each 5 MB."
      ],
      "metadata": {
        "id": "_tBtHtMZYsSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  for i in range(10):\n",
        "      with open(f'random_strings_file_{i+1}.txt', 'w') as f:\n",
        "          for _ in range(num_lines):\n",
        "              f.write(''.join(random.choices(string.ascii_letters + string.digits, k=100)) + '\\n')\n"
      ],
      "metadata": {
        "id": "r4xrxW7lY1k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4: Create 5 files of size 1GB, 2GB, 3GB, 4GB, and 5GB."
      ],
      "metadata": {
        "id": "IN0m4Zg9Y3EL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  for size in [1, 2, 3, 4, 5]:\n",
        "      with open(f'file_{size}GB.txt', 'wb') as f:\n",
        "          f.write(b'x' * size * 1024 * 1024 * 1024)\n"
      ],
      "metadata": {
        "id": "dXMaviwUcADP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5: Convert all files of Q4 into uppercase."
      ],
      "metadata": {
        "id": "phjL9f3nY-Mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  for size in [1, 2, 3, 4, 5]:\n",
        "      with open(f'file_{size}GB.txt', 'rb') as f:\n",
        "          content = f.read().upper()\n",
        "      with open(f'file_{size}GB_uppercase.txt', 'wb') as f:\n",
        "          f.write(content)\n"
      ],
      "metadata": {
        "id": "3yu-p_mKgDea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6: Convert files of Q4 into uppercase using multi-threading."
      ],
      "metadata": {
        "id": "4_pxvCmbZL6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "  def convert_to_uppercase(file):\n",
        "      with open(file, 'rb') as f:\n",
        "          content = f.read().upper()\n",
        "      with open(file.replace('.txt', '_uppercase.txt'), 'wb') as f:\n",
        "          f.write(content)\n",
        "\n",
        "  with ThreadPoolExecutor() as executor:\n",
        "      executor.map(convert_to_uppercase, [f'file_{size}GB.txt' for size in [1, 2, 3, 4, 5]])\n"
      ],
      "metadata": {
        "id": "uA7TLWinZQe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7: WAP to automatically download 10 images of cat from “Google Images”."
      ],
      "metadata": {
        "id": "54zLNY0GZhPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  import requests\n",
        "\n",
        "  url = 'https://www.google.com/search?hl=en&tbm=isch&q=cat'\n",
        "  response = requests.get(url)  # Implement logic to scrape image URLs\n",
        "  # In practice, use appropriate libraries like `requests_html` for scraping image URLs.\n"
      ],
      "metadata": {
        "id": "vQCZ06jkZkyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12: Create a random dataset of 100 rows and 30 columns."
      ],
      "metadata": {
        "id": "o0lfvs_aasgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "\n",
        "  data = pd.DataFrame(np.random.randint(1, 201, size=(100, 30)), columns=[f'Col{i}' for i in range(1, 31)])\n"
      ],
      "metadata": {
        "id": "28I4TIgzattE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(i) Replace all values with NA in the range [10, 60]. Count missing rows."
      ],
      "metadata": {
        "id": "q4HUpWIMa0z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.mask((data >= 10) & (data <= 60), np.nan)\n",
        "missing_count = data.isna().sum()\n"
      ],
      "metadata": {
        "id": "3ZtbZ2OGbAlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(ii) Replace NA values with the average of the column."
      ],
      "metadata": {
        "id": "q38R92Ctbcko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in data.columns:\n",
        "    data[col].fillna(data[col].mean(), inplace=True)\n"
      ],
      "metadata": {
        "id": "BVDmLKlabkUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(iii) Find the Pearson correlation, plot heat map."
      ],
      "metadata": {
        "id": "PA2WxKnPblkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "corr = data.corr()\n",
        "sns.heatmap(corr)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ysiE5oWUbosE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13: Create a dataset of 500 rows and 10 columns"
      ],
      "metadata": {
        "id": "6L_lpcnAgSIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(i) K-Mean clustering"
      ],
      "metadata": {
        "id": "IsfPCBtDgbWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans.fit(data)\n"
      ],
      "metadata": {
        "id": "LW2sYWwKgYRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(ii) Hierarchical clustering"
      ],
      "metadata": {
        "id": "vWvE0YgpbBp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "hc = AgglomerativeClustering(n_clusters=3)\n",
        "hc.fit(data)\n"
      ],
      "metadata": {
        "id": "dVGFQNNUgjZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14: Create a random dataset of 600 rows and 15 columns."
      ],
      "metadata": {
        "id": "XJgCEoSHgqJY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(i) Scatter Graph"
      ],
      "metadata": {
        "id": "P-6Xq-jbgrDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(data['Col5'], data['Col6'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D2TGXDQgguLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(ii) Histogram of each column\n"
      ],
      "metadata": {
        "id": "RS9sva65gx2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(data['Col5'], data['Col6'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eaM93mWDgxHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(iii) Box plot of each column"
      ],
      "metadata": {
        "id": "o2ciEv1Xg7Cr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.plot.box(figsize=(10, 10))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Lf2jukKAg_I5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}